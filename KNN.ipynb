{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.6240</td>\n",
       "      <td>21.1502</td>\n",
       "      <td>2.9085</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>50.8761</td>\n",
       "      <td>43.1887</td>\n",
       "      <td>9.8145</td>\n",
       "      <td>3.6130</td>\n",
       "      <td>238.0980</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.2468</td>\n",
       "      <td>17.3565</td>\n",
       "      <td>3.0332</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>8.5730</td>\n",
       "      <td>38.0957</td>\n",
       "      <td>10.5868</td>\n",
       "      <td>4.7920</td>\n",
       "      <td>219.0870</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.7897</td>\n",
       "      <td>13.7595</td>\n",
       "      <td>2.5521</td>\n",
       "      <td>0.4236</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>29.6339</td>\n",
       "      <td>20.4560</td>\n",
       "      <td>-2.9292</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>237.1340</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>96.2327</td>\n",
       "      <td>46.5165</td>\n",
       "      <td>4.1540</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>110.3550</td>\n",
       "      <td>85.0486</td>\n",
       "      <td>43.1844</td>\n",
       "      <td>4.8540</td>\n",
       "      <td>248.2260</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46.7619</td>\n",
       "      <td>15.1993</td>\n",
       "      <td>2.5786</td>\n",
       "      <td>0.3377</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>24.7548</td>\n",
       "      <td>43.8771</td>\n",
       "      <td>-6.6812</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>102.2510</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1       2       3       4         5        6        7   \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
       "5   51.6240   21.1502  2.9085  0.2420  0.1340   50.8761  43.1887   9.8145   \n",
       "6   48.2468   17.3565  3.0332  0.2529  0.1515    8.5730  38.0957  10.5868   \n",
       "7   26.7897   13.7595  2.5521  0.4236  0.2174   29.6339  20.4560  -2.9292   \n",
       "8   96.2327   46.5165  4.1540  0.0779  0.0390  110.3550  85.0486  43.1844   \n",
       "9   46.7619   15.1993  2.5786  0.3377  0.1913   24.7548  43.8771  -6.6812   \n",
       "\n",
       "        8         9  10  \n",
       "0  40.0920   81.8828  g  \n",
       "1   6.3609  205.2610  g  \n",
       "2  76.9600  256.7880  g  \n",
       "3  10.4490  116.7370  g  \n",
       "4   4.6480  356.4620  g  \n",
       "5   3.6130  238.0980  g  \n",
       "6   4.7920  219.0870  g  \n",
       "7   0.8120  237.1340  g  \n",
       "8   4.8540  248.2260  g  \n",
       "9   7.8750  102.2510  g  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"magic04.data\",header=None)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Balancing the data:**\n",
    "    data is balanced by splitting the gamma and hadron samples then randomly sampling a number of gamma samples equal to that of the hadron samples and then concatinating both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_data = data[data[10] == 'g'] \n",
    "hadron_data = data[data[10] == 'h']\n",
    "gamma_data_balanced = gamma_data.sample(n=len(hadron_data), random_state=42)\n",
    "balanced_data = pd.concat([gamma_data_balanced, hadron_data])\n",
    "Features = balanced_data.drop([10], axis=1)  \n",
    "Lables = balanced_data[10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing the features:\n",
    "    Features are standardized with 0 mean and unity standard deviation so that results won't be biased towards large features in distance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Features_standardized= scaler.fit_transform(Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Splitting the data:**\n",
    "    the now balanced data is partitioned into three parts 70% for training,\n",
    "    15% for validation and 15% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_train,Features_temp,Lables_train,Lables_temp=train_test_split(Features_standardized,Lables,test_size=0.3,random_state=42)\n",
    "Features_valid,Features_test,Lables_valid,Lables_test=train_test_split(Features_temp,Lables_temp,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR K=1:\n",
      "\n",
      "prediction for k=1 : ['g' 'g' 'h' ... 'h' 'h' 'g']\n",
      "accuracy for k=1 : 0.7931206380857427\n",
      "precision for k=1: 0.7770582793709528\n",
      "recall for k=1 0.8284023668639053\n",
      "f1 for k=1: 0.801909307875895\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   840                   174\n",
      "Actual Hadron (h)                  241                   751\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=5:\n",
      "\n",
      "prediction for k=5 : ['g' 'g' 'h' ... 'g' 'h' 'g']\n",
      "accuracy for k=5 : 0.8180458624127617\n",
      "precision for k=5: 0.7834061135371179\n",
      "recall for k=5 0.8846153846153846\n",
      "f1 for k=5: 0.8309402501157943\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   897                   117\n",
      "Actual Hadron (h)                  248                   744\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=11:\n",
      "\n",
      "prediction for k=11 : ['g' 'g' 'h' ... 'g' 'h' 'g']\n",
      "accuracy for k=11 : 0.8185443668993021\n",
      "precision for k=11: 0.7801724137931034\n",
      "recall for k=11 0.8925049309664694\n",
      "f1 for k=11: 0.8325666973321068\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   905                   109\n",
      "Actual Hadron (h)                  255                   737\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=15:\n",
      "\n",
      "prediction for k=15 : ['g' 'h' 'h' ... 'g' 'h' 'g']\n",
      "accuracy for k=15 : 0.8190428713858424\n",
      "precision for k=15: 0.7770212765957447\n",
      "recall for k=15 0.9003944773175543\n",
      "f1 for k=15: 0.8341708542713567\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   913                   101\n",
      "Actual Hadron (h)                  262                   730\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=19:\n",
      "\n",
      "prediction for k=19 : ['g' 'h' 'h' ... 'g' 'h' 'g']\n",
      "accuracy for k=19 : 0.8085742771684945\n",
      "precision for k=19: 0.764261744966443\n",
      "recall for k=19 0.8984220907297831\n",
      "f1 for k=19: 0.8259292837715322\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   911                   103\n",
      "Actual Hadron (h)                  281                   711\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=25:\n",
      "\n",
      "prediction for k=25 : ['g' 'h' 'h' ... 'g' 'h' 'g']\n",
      "accuracy for k=25 : 0.8090727816550349\n",
      "precision for k=25: 0.7657961246840775\n",
      "recall for k=25 0.8964497041420119\n",
      "f1 for k=25: 0.825988187187642\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   909                   105\n",
      "Actual Hadron (h)                  278                   714\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=35:\n",
      "\n",
      "prediction for k=35 : ['g' 'g' 'h' ... 'h' 'h' 'g']\n",
      "accuracy for k=35 : 0.8080757726819542\n",
      "precision for k=35: 0.761865112406328\n",
      "recall for k=35 0.9023668639053254\n",
      "f1 for k=35: 0.8261851015801355\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   915                    99\n",
      "Actual Hadron (h)                  286                   706\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=50:\n",
      "\n",
      "prediction for k=50 : ['g' 'g' 'h' ... 'g' 'h' 'g']\n",
      "accuracy for k=50 : 0.8030907278165503\n",
      "precision for k=50: 0.7530662305805397\n",
      "recall for k=50 0.908284023668639\n",
      "f1 for k=50: 0.8234242288779615\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   921                    93\n",
      "Actual Hadron (h)                  302                   690\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=60:\n",
      "\n",
      "prediction for k=60 : ['g' 'g' 'h' ... 'g' 'h' 'g']\n",
      "accuracy for k=60 : 0.8035892323030908\n",
      "precision for k=60: 0.7540983606557377\n",
      "recall for k=60 0.9072978303747534\n",
      "f1 for k=60: 0.8236347358997315\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   920                    94\n",
      "Actual Hadron (h)                  300                   692\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=75:\n",
      "\n",
      "prediction for k=75 : ['g' 'g' 'h' ... 'g' 'h' 'g']\n",
      "accuracy for k=75 : 0.806580259222333\n",
      "precision for k=75: 0.7586776859504132\n",
      "recall for k=75 0.9053254437869822\n",
      "f1 for k=75: 0.8255395683453237\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   918                    96\n",
      "Actual Hadron (h)                  292                   700\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=85:\n",
      "\n",
      "prediction for k=85 : ['g' 'g' 'h' ... 'h' 'h' 'g']\n",
      "accuracy for k=85 : 0.8055832502492523\n",
      "precision for k=85: 0.7578512396694215\n",
      "recall for k=85 0.9043392504930966\n",
      "f1 for k=85: 0.8246402877697842\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   917                    97\n",
      "Actual Hadron (h)                  293                   699\n",
      "---------------------------------------------------------------------------\n",
      "RESULTS FOR K=100:\n",
      "\n",
      "prediction for k=100 : ['g' 'g' 'h' ... 'h' 'h' 'g']\n",
      "accuracy for k=100 : 0.80259222333001\n",
      "precision for k=100: 0.7532786885245901\n",
      "recall for k=100 0.9063116370808678\n",
      "f1 for k=100: 0.8227394807520143\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   919                    95\n",
      "Actual Hadron (h)                  301                   691\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_ranges=[1,5,11,15,19,25,35,50,60,75,85,100]\n",
    "bestF1=0\n",
    "best_K_F1=0\n",
    "best_model_F1=None\n",
    "for k in k_ranges:\n",
    "    total=0\n",
    "    print(f\"RESULTS FOR K={k}:\\n\")\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(Features_train,Lables_train)\n",
    "    predict_valid=knn_model.predict(Features_valid)\n",
    "    print(f\"prediction for k={k} :\",predict_valid)\n",
    "\n",
    "    accuracy=accuracy_score(Lables_valid,predict_valid)#correctly predicted/total \n",
    "    print(f\"accuracy for k={k} :\",accuracy)\n",
    "\n",
    "    precision= precision_score(Lables_valid,predict_valid,pos_label=\"g\")#tp/tp+fp\n",
    "    print(f\"precision for k={k}:\",precision)\n",
    "    \n",
    "    recall=recall_score(Lables_valid,predict_valid,pos_label=\"g\")#tp/tp+fn\n",
    "    print(f\"recall for k={k}\",recall)\n",
    "\n",
    "    f1 = f1_score(Lables_valid,predict_valid,pos_label=\"g\")#2*tp/2*tp+fp+fn\n",
    "    print(f\"f1 for k={k}:\",f1)\n",
    "\n",
    "    cm=confusion_matrix(Lables_valid,predict_valid,labels=[\"g\",\"h\"])\n",
    "    cm_df = pd.DataFrame(cm, index=[\"Actual Gamma (g)\", \"Actual Hadron (h)\"], columns=[\"Predicted Gamma (g)\", \"Predicted Hadron (h)\"])\n",
    "    print(\"\\n\",cm_df)  \n",
    "    \n",
    "    if bestF1<f1:\n",
    "        bestF1=f1\n",
    "        best_K_F1=k\n",
    "        best_model_F1=knn_model     \n",
    "\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results after tuning K according to F-score:\n",
      "\n",
      "prediction for k=15 : ['g' 'g' 'h' ... 'h' 'g' 'g']\n",
      "accuracy for k=15 : 0.8231190832087693\n",
      "precision for k=15: 0.7796754910333049\n",
      "recall for k=15 0.903960396039604\n",
      "f1 for k=15: 0.8372306281522237\n",
      "\n",
      "                    Predicted Gamma (g)  Predicted Hadron (h)\n",
      "Actual Gamma (g)                   913                    97\n",
      "Actual Hadron (h)                  258                   739\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test results after tuning K according to F-score:\\n\")\n",
    "predict_test=best_model_F1.predict(Features_test)\n",
    "print(f\"prediction for k={best_K_F1} :\",predict_test)\n",
    "\n",
    "accuracy=accuracy_score(Lables_test,predict_test)#correctly predicted/total \n",
    "print(f\"accuracy for k={best_K_F1} :\",accuracy)\n",
    "\n",
    "precision= precision_score(Lables_test,predict_test,pos_label=\"g\")#tp/tp+fp\n",
    "print(f\"precision for k={best_K_F1}:\",precision)\n",
    "    \n",
    "recall=recall_score(Lables_test,predict_test,pos_label=\"g\")#tp/tp+fn\n",
    "print(f\"recall for k={best_K_F1}\",recall)\n",
    "\n",
    "f1 = f1_score(Lables_test,predict_test,pos_label=\"g\")#2*tp/2*tp+fp+fn\n",
    "print(f\"f1 for k={best_K_F1}:\",f1)\n",
    "\n",
    "cm=confusion_matrix(Lables_test,predict_test,labels=[\"g\",\"h\"])\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual Gamma (g)\", \"Actual Hadron (h)\"], columns=[\"Predicted Gamma (g)\", \"Predicted Hadron (h)\"])\n",
    "print(\"\\n\",cm_df) \n",
    "print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comments**:\n",
    "\n",
    "##### Accuracy:\n",
    "    accuracy is improved by increasing K for lower values of K and peaks at K=15,then proceeds to steadily decline for the larger values of K which suggests that larger K values may be causing underfitting\n",
    "##### Percision:\n",
    "    percision remains relatively consisitent for the smaller values of K but shows a slight decrease for the larger values\n",
    "##### Recall:\n",
    "    recall consistently increases with the increase of K except for the very large values of K i.e:K>50 \n",
    "##### F-Score:\n",
    "    represents a balance of percision and recall by balancing minimizing false positives and false negatives and peaks at K=15\n",
    "##### Conclusion:\n",
    "    Choosing F-Score as the deciding factor in this classification problem is because of the importance of identifying gamma particles correctly by minimizing false positives and false negatives.\n",
    "    15 is chosen for the K value after tuning for F-score.\n",
    "    This yields the following test results:\n",
    "* accuracy=82.3%\n",
    "* percision=77.9%\n",
    "* recall=90.3%\n",
    "* F-Score=83.7%\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
